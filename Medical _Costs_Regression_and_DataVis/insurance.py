# -*- coding: utf-8 -*-
"""insurance.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ylmLtlI8yTp-OENIjxv8UuQzTikkIeyv
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

insurance=pd.read_csv('/content/insurance.csv')

insurance.head()

insurance.shape
#number of rows and columns in the data set

sns.set(rc={"figure.figsize":(6,6)})
#determined my plots size

insurance.info()
#as it is seen no null type

# Perform An Exploratory Data Analysis

plt.hist(insurance["bmi"])
plt.xlabel("bmi")
plt.ylabel("frequency")
#examined distribution of bmi. (bu grafikte hangi bmi'nin ne sıklıkla dağıldığını görüyoruz.)
#normal distribution

plt.figure(figsize=(4,4))
sns.barplot(x="smoker",y="charges",data=insurance)
plt.title("Relationship between smoker and charges")
#Here we see that smokers pay much more non-smokers. (sigara içenlerin içmeyenlere göre daha fazla ödediğini görüyoruz.)

plt.figure(figsize=(6,4))
sns.countplot(x="region",data=insurance, hue="smoker")
plt.title("Relationship between region and smoker")
#this plot shows that the count of non-smokers more than smokers in all regions.
#the most smokers in southeast.

plt.figure(figsize=(4,4))
sns.barplot(x="sex",y="bmi",data=insurance)
plt.title("Relationship between sex and bmi")

sex=insurance.groupby("sex",as_index=False)["bmi"].mean()
sex
#after founding mean of bmi.That shows us truth of up barplot.

sns.barplot(x="region", y="children", data=insurance)
#the most children are in northwest

plt.figure(figsize=(5,5))
sns.scatterplot(x="age" , y="bmi", data=insurance)
#this scatter plot shows some young persons have high bmi.

sns.boxplot(x="children", y="bmi", data=insurance)
plt.title("Relationship between children and bmi")
#who have 2 children has may more bmi.
#there are points outside the observations so there is outlier in the bmi varible.
#(boxplot dışında noktalar var bu da outlier olduğunu gösterir.)
#(örneğin 1 çocukluya baktığımzda gözlem dışında veriler olduğunu görüyoruz.)

plt.figure(figsize=(5,5))
sns.scatterplot(x="charges" , y="bmi", data=insurance)
plt.title("relationship between bmi and charges")
#as it seen when bmi is its mean point charges may rise.
#bmi ortalama değerinde daha fazla ödeme yapılıyor.

sns.barplot(x="bmi", y="region", hue="smoker",data=insurance)
plt.title("relationship between region-bmi-smoker")

#using boxplot which value is outlier. For example;
plt.figure(figsize=(4,2))
sns.boxplot(x="bmi", data=insurance)

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# test train split for supervised training
X_train,X_test,y_train,y_test = train_test_split( insurance.bmi, insurance.charges)

# test train split visualization
plt.scatter(X_train,y_train, label='Training Data', color='b',alpha=.7)
plt.scatter(X_test,y_test, label='Testing Data',color='g',alpha=.7)
plt.legend()
plt.title("Test Train Split")
plt.show()

# create linear model and train it
Lr=LinearRegression()
Lr.fit(X_train.values.reshape(-1,1), y_train.values)

# use model to predict on Test Data
prediction= Lr.predict(X_test.values.reshape(-1,1))

# plot prediction line against actual test data
plt.plot(X_test, prediction, label='Linear Regression', color='r' )
plt.scatter(X_test, y_test, label='Actual Test Data',color='g', alpha=.7)
plt.legend()
plt.show()

# predict charge of bmi is 40
Lr.predict(np.array([[40]]))[0]

# score this model
Lr.score(X_test.values.reshape(-1,1), y_test.values)

"""low accuracy score (near 0) indicates that the model needs to be improved"""

from sklearn.linear_model import LogisticRegression

insurance.sample(7)

# Feature Engineering (one hot encoding)
insurance=pd.get_dummies(insurance, drop_first=True)
insurance.head()

#Test train split
X_train, X_test, y_train, y_test = train_test_split(insurance.drop('smoker_yes',axis=1), insurance['smoker_yes'])

#Train the model using training data
LogReg= LogisticRegression()
LogReg.fit(X_train, y_train)

#score the model
LogReg.score(X_test, y_test)

"""so it is a good model :)"""

LogReg.predict(np.array([[21,32,0,14000,0,0,0,0]]))[0]

"""the logistic regression may not practical for this data"""

# KNN REGRESSION MODEL

y = insurance.age
X = insurance.drop(["age"], axis = 1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20)

from sklearn.neighbors import KNeighborsRegressor

knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(X_train, y_train)
knn_predict = knn.predict(X_test)

knn.score(X_test, y_test)

knn_predict = knn.predict(X_test)
df_KNNRegressor = pd.DataFrame({'Actual': y_test, 'Predicted': knn_predict})
df_KNNRegressor.sample(5)

#  MODEL EVALUATION

from sklearn import metrics

print('Mean Absolute Error -->', metrics.mean_absolute_error(y_test, knn_predict))

print('Mean Squared Error -->', metrics.mean_squared_error(y_test, knn_predict))

from sklearn.preprocessing import MinMaxScaler

minmax = MinMaxScaler()
X_train_scaled = minmax.fit_transform(X_train)
X_test_scaled = minmax.transform(X_test)

